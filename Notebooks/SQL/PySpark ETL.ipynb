{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark ETL\n",
    "This example will show how to use SparkSql to perform ETL on a set of relational tables\n",
    "<br>\n",
    "<br>\n",
    "**Tables**:\n",
    "1. Customer: Information such as State, Gender and Customer ID\n",
    "2. Product: List of SKUs the retail chain s ells\n",
    "3. Transaction: Point of Sale (POS) data for customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create Spark Session\n",
    "spark=SparkSession.builder.appName(\"simple\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Files from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+-----------+--------------------+----------+--------------------+--------------+\n",
      "|CustomerID|State|Gender|  FirstName|            LastName|Birth_Date|             Address|Member_Type_ID|\n",
      "+----------+-----+------+-----------+--------------------+----------+--------------------+--------------+\n",
      "|         1|   KY|     M|     Albert|              Collet| 24Nov1940|Square Edouard Vii 1|          2030|\n",
      "|         2|   ME|     F|   Mercedes|            Mart�nez| 15Jan1955|          Edificio 2|          1010|\n",
      "|         3|   IN|     M|Pier Egidio|              Boeris| 01Jul1970|Via M. Di Monteso...|          1040|\n",
      "|         4|   NY|     M|      James|             Kvarniq| 27Jun1970|      4382 Gralyn Rd|          1020|\n",
      "|         5|   NY|     F|   Sandrina|            Stephano| 09Jul1975|    6468 Cog Hill Ct|          2020|\n",
      "|         6|   OH|     M|       Rent|            Van Lint| 23Dec1945|         Mispadstr 2|          1030|\n",
      "|         7|   ME|     F|     Juli�n|Escorihuela Monse...| 07Aug1975|Co. De Los Clavel...|          1040|\n",
      "|         8|   KY|     M|        Aki|              Ivonen| 04Dec1935|         Valimotie 5|          1020|\n",
      "|         9|   OH|     F|   Cornelia|               Krahl| 27Feb1970|   Kallstadterstr. 9|          2020|\n",
      "|        10|   NY|     F|      Karen|           Ballinger| 18Oct1980|425 Bryant Estate...|          1040|\n",
      "+----------+-----+------+-----------+--------------------+----------+--------------------+--------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "#Read in Customer file from HDFS\n",
    "Customer = spark.read.csv('hdfs://localhost:54310/user/andrew/data/relational_example/Customer.csv', header=True)\n",
    "\n",
    "#Register for SQL Use\n",
    "Customer.createOrReplaceTempView(\"Customer\")\n",
    "\n",
    "Customer.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+-------+\n",
      "|itemcode|                item|   category| Amount|\n",
      "+--------+--------------------+-----------+-------+\n",
      "|     111|             SEP IRA| Retirement|$550.00|\n",
      "|     112|              Keough| Retirement|$325.00|\n",
      "|     113|          Simple IRA| Retirement|$125.00|\n",
      "|     114|         US Equities|Mutual Fund|  $2.80|\n",
      "|     115|International Equ...|Mutual Fund|$325.00|\n",
      "|     116|      Lifestyle Fund|Mutual Fund|$245.00|\n",
      "|     117|        Money Market|Mutual Fund|$268.00|\n",
      "|     118|Mutual Fund - US ...|Mutual Fund| $75.00|\n",
      "|     121|    Asset Allocation|Mutual Fund|$850.00|\n",
      "|     122|        Fixed Income|Mutual Fund|$268.00|\n",
      "+--------+--------------------+-----------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "#Read in Customer file from HDFS\n",
    "Product = spark.read.csv('hdfs://localhost:54310/user/andrew/data/relational_example/Product.csv', header=True)\n",
    "\n",
    "#Register for SQL Use\n",
    "Product.createOrReplaceTempView(\"Product\")\n",
    "\n",
    "Product.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------+----------+-----------+---------+\n",
      "|order_number|quantity|itemcode|order_type|Customer_ID|     date|\n",
      "+------------+--------+--------+----------+-----------+---------+\n",
      "|        1002|       1|     324|         1|          2|02Jan2016|\n",
      "|        1002|       1|     322|         1|          2|02Jan2016|\n",
      "|        1001|       1|     322|         0|          1|02Jan2016|\n",
      "|        1003|       1|     324|         1|          3|04Jan2016|\n",
      "|        1004|       1|     324|         1|          4|04Jan2016|\n",
      "|        1005|       2|     314|         1|          5|04Jan2016|\n",
      "|        1006|       1|     314|         0|          6|05Jan2016|\n",
      "|        1007|       1|     323|         0|          7|05Jan2016|\n",
      "|        1008|       1|     323|         0|          8|08Jan2016|\n",
      "|        1009|       4|     221|         1|          9|08Jan2016|\n",
      "+------------+--------+--------+----------+-----------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "#Read in Customer file from HDFS\n",
    "Transaction = spark.read.csv('hdfs://localhost:54310/user/andrew/data/relational_example/Transaction.csv', header=True)\n",
    "\n",
    "#Register for SQL Use\n",
    "Product.createOrReplaceTempView(\"Transaction\")\n",
    "\n",
    "Transaction.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+\n",
      "|database|  tableName|isTemporary|\n",
      "+--------+-----------+-----------+\n",
      "|        |   customer|       true|\n",
      "|        |    product|       true|\n",
      "|        |transaction|       true|\n",
      "+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.12\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
